{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1148b5-a2fb-4b3f-9a7c-e87e28e42ec3",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "\n",
    "First, we will get the embeddings model `multi-qa-distilbert-cos-v1` from\n",
    "[the Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)\n",
    "\n",
    "```bash\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "```\n",
    "\n",
    "Create the embedding for this user question:\n",
    "\n",
    "```python\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "```\n",
    "\n",
    "What's the first value of the resulting vector?\n",
    "\n",
    "* -0.24\n",
    "* -0.04\n",
    "* 0.07\n",
    "* 0.27\n",
    "\n",
    "\n",
    "## Prepare the documents\n",
    "\n",
    "Now we will create the embeddings for the documents.\n",
    "\n",
    "Load the documents with ids that we prepared in the module:\n",
    "\n",
    "```python\n",
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "```\n",
    "\n",
    "We will use only a subset of the questions - the questions\n",
    "for `\"machine-learning-zoomcamp\"`. After filtering, you should\n",
    "have only 375 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c0bd19-dcee-4db3-ba27-277b7e234d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexei/miniconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07822263\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# User question\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "\n",
    "# Create embedding for the user question\n",
    "embedding = embedding_model.encode(user_question)\n",
    "# Get the first value of the resulting vector\n",
    "first_value = embedding[0]\n",
    "print(first_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3db9b3-2925-46f2-8641-74f003074531",
   "metadata": {},
   "source": [
    "**Answer:** 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d8d0ff-ecd9-4fae-9ed3-608e19d7b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc3d210-0bd5-4241-8c0c-507533cd35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_zoomcamp_docs = [doc for doc in documents if doc[\"course\"] == \"machine-learning-zoomcamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5b5d59-ff22-4443-a3f5-1c9c95dac0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository thereâ€™s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'How do I sign up?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'id': '0227b872'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_zoomcamp_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc23c3-2fe2-4c78-b57e-979afc597e1e",
   "metadata": {},
   "source": [
    "## Q2. Creating the embeddings\n",
    "\n",
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "We want to put all of them into a single matrix `X`:\n",
    "\n",
    "- Create a list `embeddings` \n",
    "- Iterate over each document \n",
    "- `qa_text = f'{question} {text}'`\n",
    "- compute the embedding for `qa_text`, append to `embeddings`\n",
    "- At the end, let `X = np.array(embeddings)` (`import numpy as np`) \n",
    "\n",
    "What's the shape of X? (`X.shape`). Include the parantheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9c3919-2a30-42ee-a4c6-9755ddc2cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21aa6243-e632-406c-8d0a-770dc1cb3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each document\n",
    "for doc in ml_zoomcamp_docs:\n",
    "    qa_text = f'{doc[\"question\"]} {doc[\"text\"]}'\n",
    "    embedding = embedding_model.encode(qa_text)\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c07992a-0324-44f8-82b5-caa8d5901b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of embeddings to a NumPy array\n",
    "X = np.array(embeddings)\n",
    "\n",
    "# Output the shape of X\n",
    "X_shape = X.shape\n",
    "X_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b8154-ca8c-4545-83d7-95a56789a85f",
   "metadata": {},
   "source": [
    "**Answer:** (375, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fdc83c-e68c-4669-ba19-6cb986beeb1e",
   "metadata": {},
   "source": [
    "## Q3. Search\n",
    "\n",
    "We have the embeddings and the query vector. Now let's compute the \n",
    "cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2. \n",
    "\n",
    "The vectors returned from the embedding model are already\n",
    "normalized (you can check it by computing a dot product of a vector\n",
    "with itself - it should return something very close to 1.0). This means that in order\n",
    "to compute the coside similarity, it's sufficient to \n",
    "multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "\n",
    "- 65.0 \n",
    "- 6.5\n",
    "- 0.65\n",
    "- 0.065\n",
    "\n",
    "\n",
    "## Vector search\n",
    "\n",
    "We can now compute the similarity between a query vector and all the embeddings.\n",
    "\n",
    "Let's use this to implement our own vector search\n",
    "\n",
    "```python\n",
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)\n",
    "```\n",
    "\n",
    "If you don't understand how the `search` function work:\n",
    "\n",
    "* Ask ChatGTP or any other LLM of your choice to explain the code\n",
    "* Check our pre-course workshop about implementing a search engine [here](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "\n",
    "(Note: you can replace `argsort` with `argpartition` to make it a lot faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22cf52d4-6a5e-4e5a-9fc8-a7b04c7e2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User question\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "\n",
    "# Create embedding for the user question\n",
    "v = embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87eabf7d-aba5-468c-a47b-ecd796a1a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65065724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = X.dot(v)\n",
    "np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270663d-f541-44d9-a7a6-d6bb4b1af572",
   "metadata": {},
   "source": [
    "**Answer:** 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e9a97-42bf-4690-aa1e-8a97bf931b3e",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "Let's evaluate the performance of our own search engine. We will\n",
    "use the hitrate metric for evaluation.\n",
    "\n",
    "First, load the ground truth dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "\n",
    "Now use the code from the module to calculate the hitrate of\n",
    "`VectorSearchEngine` with `num_results=5`.\n",
    "\n",
    "What did you get?\n",
    "\n",
    "* 0.93\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51702130-9317-4488-8109-926c017d447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12ae1e57-7812-4f55-a1f8-a96f41d37bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c709de-4eb1-4274-b924-caee475b0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55ffdb3c-a3a0-4ee5-8eea-7f84a8456f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the search engine\n",
    "search_engine = VectorSearchEngine(documents=ml_zoomcamp_docs, embeddings=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dfa022c-d884-4e27-a752-7a1d306dd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate hitrate\n",
    "def calculate_hitrate(search_engine, ground_truth, num_results=5):\n",
    "    hits = 0\n",
    "    for item in ground_truth:\n",
    "        query = item['question']\n",
    "        true_document_id = item['document']\n",
    "        query_embedding = embedding_model.encode(query)\n",
    "        results = search_engine.search(query_embedding, num_results=num_results)\n",
    "        if any(result['id'] == true_document_id for result in results):\n",
    "            hits += 1\n",
    "    return hits / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c5dcbff-5d39-4279-af5c-6ba85df9bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398907103825137"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_hitrate(search_engine, ground_truth, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad353e-0cb6-486e-ac1e-002ba04b4f07",
   "metadata": {},
   "source": [
    "**Answer:** 0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9d545-aa3b-4a99-a4b2-22e47c4639aa",
   "metadata": {},
   "source": [
    "## Q5. Indexing with Elasticsearch\n",
    "\n",
    "Now let's index these documents with elasticsearch\n",
    "\n",
    "* Create the index with the same settings as in the module (but change the dimensions)\n",
    "* Index the embeddings (note: you've already computed them)\n",
    "\n",
    "After indexing, let's perform the search of the same query from Q1.\n",
    "\n",
    "What's the ID of the document with the highest score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e907b243-b2aa-4f47-9126-9f46251e1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "201286fc-42c3-4485-bda1-4f3ecf38f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "973faae5-b15a-41c3-bd3e-6e34745ae554",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 1\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"text\"},\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 768}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7a55e22-672e-4df9-b0c1-b9e699255660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ml_zoomcamp_index'})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the index\n",
    "es.indices.create(index=\"ml_zoomcamp_index\", body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "731ff7cc-4ea9-4983-ba65-c4dde5580430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of documents and corresponding embeddings\n",
    "for doc, emb in zip(ml_zoomcamp_docs, embeddings):\n",
    "    es.index(index=\"ml_zoomcamp_index\", body={\n",
    "        \"text\": doc[\"text\"],\n",
    "        \"section\": doc[\"section\"],\n",
    "        \"question\": doc[\"question\"],\n",
    "        \"course\": doc[\"course\"],\n",
    "        \"embedding\": emb.tolist()  # Convert NumPy array to list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a60027c6-da31-40fd-873c-9b7d75d5fe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: Ml4GwJAB6701txdGLBcz, Score: 1.6506574\n"
     ]
    }
   ],
   "source": [
    "query = \"I just discovered the course. Can I still join it?\"\n",
    "query_embedding = embedding_model.encode(query).tolist()\n",
    "\n",
    "# Define the search query\n",
    "search_query = {\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                \"params\": {\"query_vector\": query_embedding}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform the search\n",
    "results = es.search(index=\"ml_zoomcamp_index\", body=search_query)\n",
    "\n",
    "# Print the ID of the document with the highest score\n",
    "top_hit = results['hits']['hits'][0]\n",
    "print(f\"Document ID: {top_hit['_id']}, Score: {top_hit['_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2496486c-d5ce-40cd-b799-16db1e0c13fd",
   "metadata": {},
   "source": [
    "**Answer:** Document ID: Ml4GwJAB6701txdGLBcz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91dbf48-37a0-4a14-99f6-58ba2f057715",
   "metadata": {},
   "source": [
    "## Q6. Hit-rate for Elasticsearch\n",
    "\n",
    "The search engine we used in Q4 computed the similarity between\n",
    "the query and ALL the vectors in our database. Usually this is \n",
    "not practical, as we may have a lot of data.\n",
    "\n",
    "Elasticsearch uses approximate techniques to make it faster. \n",
    "\n",
    "Let's evaluate how worse the results are when we switch from\n",
    "exact search (as in Q4) to approximate search with Elastic.\n",
    "\n",
    "What's hitrate for our dataset for Elastic?\n",
    "\n",
    "* 0.93\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b79b6c79-a8ed-49dd-8a57-b78de0e42395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_based_hitrate(ground_truth, index_name, num_results=5):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    for item in ground_truth:\n",
    "        query_text = item['question']\n",
    "        true_document_id = item['document']\n",
    "\n",
    "        search_query = {\n",
    "            \"size\": num_results,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query_text,\n",
    "                            \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"course\": \"machine-learning-zoomcamp\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        results = es.search(index=index_name, body=search_query)\n",
    "        result_ids = [hit['_id'] for hit in results['hits']['hits']]\n",
    "\n",
    "        if true_document_id in result_ids:\n",
    "            hits += 1\n",
    "        total += 1\n",
    "\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae38fa1c-74b1-4cf7-8a5c-87b5a116021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-based hitrate for Elasticsearch: 0.00\n"
     ]
    }
   ],
   "source": [
    "hitrate_text_based = calculate_text_based_hitrate(ground_truth, \"ml_zoomcamp_index\")\n",
    "print(f\"Text-based hitrate for Elasticsearch: {hitrate_text_based:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
